"\nверни json {\n\"title\": короткий кликбейт заголовок-мнение для текста на русском языке,\n\n\"description\": главные тезисы текста в художественно-публицистическом жанре с использованием одного образного сравнения длиной 2 предложения по 15 слов на русском языке, \n\n\"morality\": веселый, оптимистический  совет на основе вывода из текста на русском языке длиной 1 предложение\n\n},  \n\nтекст -\n Researchers have identified a network of brain regions that work together to determine if a robot is a worthy social partner, according to a new study published in Journal of Neuroscience. Using functional magnetic resonance imaging, Astrid Rosenthal-von der Pütten, Fabien Grabenhorst, and colleagues evaluated brain activity from the prefrontal cortex and amygdala as human participants scored images of robots on their likability, familiarly, and human-likeness. The participants also chose the robot from which they would prefer to receive a gift, indicating their social value. Participants preferred more lifelike robots but disliked the ones that appeared “too human,” including artificially altered humans. Activity in the ventromedial prefrontal cortex followed the same pattern, increasing with the more lifelike robots until dropping significantly in relation to the most lifelike choice. The scientists concluded that each of several brain regions had a unique role in assessing the images, and the combination of their inputs determined whether or not a robot was likable. This direct representation of a psychological pattern in the brain provides insight into how people respond to and assess artificial social partners. The findings may also apply to the evaluation of human social partners. Source: SfN Media Contacts:  Calli McMurray – SfN Image Source: The image is credited to Rosenthal-von der Pütten et al., JNeurosci 2019. Artificial agents are becoming prevalent across human life domains. However, the neural mechanisms underlying human responses to these new, artificial social partners remain unclear. The Uncanny-Valley (UV) hypothesis predicts that humans prefer anthropomorphic agents but reject them if they become too human-like—the so-called UV reaction. Using functional MRI, we investigated neural activity when subjects evaluated artificial agents and made decisions about them. Across two experimental tasks, the ventromedial prefrontal cortex (VMPFC) encoded an explicit representation of subjects’ UV reactions. Specifically, VMPFC signaled the subjective likability of artificial agents as a nonlinear function of human-likeness, with selective low likability for highly humanlike agents. In exploratory across-subject analyses, these effects explained individual differences in psychophysical evaluations and preference choices. Functionally connected areas encoded critical inputs for these signals: the temporo-parietal junction encoded a linear human-likeness continuum, whereas nonlinear representations of human-likeness in dorsomedial prefrontal cortex (DMPFC) and fusiform gyrus emphasized a human-nonhuman distinction. Following principles of multisensory integration, multiplicative combination of these signals reconstructed VMPFC’s valuation function. During decision-making, separate signals in VMPFC and DMPFC encoded subjects’ decision variable for choices involving humans or artificial agents, respectively. A distinct amygdala signal predicted rejection of artificial agents. Our data suggest that human reactions toward artificial agents are governed by a neural mechanism that generates a selective, nonlinear valuation in response to a specific feature combination (human-likeness in nonhuman agents). Thus, a basic principle known from sensory coding—neural feature selectivity from linear-nonlinear transformation—may also underlie human responses to artificial social partners. Would you trust a robot to make decisions for you? Autonomous artificial agents are increasingly entering our lives but how the human brain responds to these new, artificial social partners remains unclear. The Uncanny Valley hypothesis—an influential psychological framework—captures the observation that human responses to artificial agents are nonlinear: we like increasingly anthropomorphic artificial agents, but feel uncomfortable if they become too human-like. Here we investigated neural activity when humans evaluated artificial agents and made personal decisions about them. Our findings suggest a novel neurobiological conceptualization of human responses toward artificial agents: The Uncanny Valley reaction—a selective dislike of highly human-like agents—is based on nonlinear value-coding in VMPFC, a key component of the brain’s reward system."